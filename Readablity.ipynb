{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/kimkwangil/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_punctuation = lambda w: not (len(w)==1 and (not w.isalpha()))\n",
    "get_word_count = lambda text: len(filter(not_punctuation, word_tokenize(text)))\n",
    "get_sent_count = lambda text: len(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "prondict = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsyllables_pronlist = lambda l: len(filter(lambda s: isdigit(s.encode('ascii', 'ignore').lower()[-1]), l))\n",
    "def numsyllables(word):\n",
    "  try:\n",
    "    return list(set(map(numsyllables_pronlist, prondict[word.lower()])))\n",
    "  except KeyError:\n",
    "    return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_statistics(text):\n",
    "  word_count = get_word_count(text)\n",
    "  sent_count = get_sent_count(text)\n",
    "  syllable_count = sum(map(lambda w: max(numsyllables(w)), word_tokenize(text)))\n",
    "  return word_count, sent_count, syllable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_formula = lambda word_count, sent_count, syllable_count : 206.835 - 1.015*word_count/sent_count - 84.6*syllable_count/word_count\n",
    "def flesch(text):\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return flesch_formula(word_count, sent_count, syllable_count)\n",
    " \n",
    "fk_formula = lambda word_count, sent_count, syllable_count : 0.39 * word_count / sent_count + 11.8 * syllable_count / word_count - 15.59\n",
    "def flesch_kincaid(text):\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return fk_formula(word_count, sent_count, syllable_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-28c173478462>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-28c173478462>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print flesch(macbeth)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "macbeth = gutenberg.raw('shakespeare-macbeth.txt')\n",
    "print flesch(macbeth)\n",
    "print flesch_kincaid(macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-589bfe28aa17>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-589bfe28aa17>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print flesch(kjv)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "kjv = gutenberg.raw('bible-kjv.txt')\n",
    "print flesch(kjv)\n",
    "print flesch_kincaid(kjv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tutorialspoint.com/readability-index-in-python-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-a4486d3e926a>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-a4486d3e926a>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    syllable + = word.count(vowel)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dire = os.getcwd()\n",
    "listOfdir = os.listdir(dire)\n",
    "while True:\n",
    "   UserFileName = input('Enter file name:')\n",
    "   if (UserFileName in listOfdir) and (UserFileName.endswith(\".txt\")):\n",
    "      InputFile = open(UserFileName,'r')\n",
    "      text = InputFile.read()\n",
    "      sentence = text.count('.') + text.count('!') + text.count(';') + text.count(':') + text.count('?')\n",
    "      words = len(text.split())\n",
    "      syllable = 0\n",
    "      for word in text.split():\n",
    "         for vowel in ['a','e','i','o','u']:\n",
    "            syllable + = word.count(vowel)\n",
    "         for ending in ['es','ed','e']:\n",
    "            if word.endswith(ending):\n",
    "               syllable - = 1\n",
    "         if word.endswith('le'):\n",
    "            syllable + = 1\n",
    "      G = round((0.39*words)/sentence+ (11.8*syllable)/words-15.59)\n",
    "      if G > = 0 and G < = 30:\n",
    "         print ('The Readability level is College')\n",
    "      elif G > = 50 and G < = 60:\n",
    "         print ('The Readability level is High School')\n",
    "      elif G > = 90 and G < = 100:\n",
    "         print ('The Readability level is fourth grade')\n",
    "      print ('This text has %d words' %(words))\n",
    "   elif UserFileName not in listOfdir:\n",
    "      print ('This text file does not exist in current directory')\n",
    "   elif not(UserFileName.endswith('.txt')):\n",
    "      print ('This is not a text file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://levelup.gitconnected.com/determine-the-reading-level-of-a-text-with-python-d2f9dccee6bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://statkclee.github.io/nlp2/nlp-twitter-ml.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "읽기 점수 계산을 위해서 textatistic 라이브러리가 필요한데 다음 명령어를 쉘에서 입력하게 되면 수월하게 설치할 수 있다.\n",
    "\n",
    "$ pip install textatistic\n",
    "\n",
    "stackoverflow를 참조하여 영화 리뷰데이터를 가져와서 읽기 점수를 산출해본다. textatistic 0.0.1을 참조하면 다양한 읽기점수 통계량을 확인할 수 있다.\n",
    "\n",
    "dalechall_score: Dale-Chall score.\n",
    "flesch_score: Flesch Reading Ease score.\n",
    "fleschkincaid_score: Flesch-Kincaid score.\n",
    "gunningfog_score : Gunning Fog score.\n",
    "smog_score: SMOG score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/textatistic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project description\n",
    "Textatistic is a Python package to calculate the Flesch Reading Ease, Flesch-Kincaid, Gunning Fog, Simple Measure of Gobbledygook (SMOG) and Dale-Chall readability indices. Textatistic also contains functions to count the number of sentences, characters, syllables, words, words with three or more syllables and words on an expanded Dale-Chall list of easy words.\n",
    "\n",
    "Installation\n",
    "$ pip install textatistic\n",
    "Documentation\n",
    "Detailed documentation available at erinhengel.com.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.erinhengel.com/software/textatistic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textatistic import Textatistic\n",
    "\n",
    "import nltk\n",
    "read_data='essay/collegeEssay01.txt'\n",
    "with open(read_data) as files:\n",
    "    contents = files.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Textatistic(contents)\n",
    "\n",
    "# Return sentence count.\n",
    "s.sent_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.26307422802853"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return Flesch Reading Ease score.\n",
    "s.flesch_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
